version: '3.6'

volumes:
  shared-workspace:
    name: "hdfs-fake-2"
    driver: local

networks:
    cluster-network-1:
        attachable: true

services :
  jupyterlab:
    image: jkanclerz/ds-jupyter:latest
    container_name: jupyterlab
    ports:
      - 8888:8888
    volumes:
      - ./:/opt/workspace
    networks:
      - cluster-network-1
  
  spark-master:
    image: jkanclerz/ds-spark-master:latest
    container_name: spark-master
    ports:
      - 8001:8080
      - 7077:7077
    volumes:
      - ./:/opt/workspace
    networks:
      - cluster-network-1

  spark-worker-1:
    image: jkanclerz/ds-spark-worker:latest
    container_name: spark-worker-1
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
    ports:
      - 8002:8081
    volumes:
      - ./:/opt/workspace
    depends_on:
      - spark-master
    networks:
      - cluster-network-1
  
  spark-worker-2:
    image: jkanclerz/ds-spark-worker:latest
    container_name: spark-worker-2
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
    ports:
      - 8003:8081
    volumes:
      - ./:/opt/workspace
    depends_on:
      - spark-master
    networks:
      - cluster-network-1

  datascience:
    image: postgres:13-alpine
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: datascience
      POSTGRES_PASSWORD: datascience
      POSTGRES_DB: datascience
    restart: always
 
  mongodb:
    image: mongo:3-xenial
    container_name: mongodb
    ports:
      - "27017:27017"
    restart: always
    networks:
      - cluster-network-1
  
  redis:
    image: redis:6-alpine
    ports:
      - 6379:6379
    restart: always

  admin:
    image: adminer
    restart: always
    depends_on: 
      - datascience
    ports:
      - 8080:8080
