{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n",
    "\n",
    "```json\n",
    "{\n",
    "  imie,\n",
    "  nazwisko,\n",
    "  wiek,\n",
    "  plec,\n",
    "  dom: {\n",
    "    ulica,\n",
    "    numer_domu,\n",
    "    kod_pocztowy,\n",
    "    miasto,\n",
    "    wojewodztwo,\n",
    "    telefon\n",
    "  },\n",
    "  praca: {\n",
    "    firma,\n",
    "    stanowisko,\n",
    "    ulica,\n",
    "    numer_domu,\n",
    "    kod_pocztowy,\n",
    "    miasto,\n",
    "    telefon,\n",
    "    wynagrodzenie\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in /usr/local/lib/python3.7/dist-packages (5.6.0)\n",
      "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.7/dist-packages (from faker) (1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.7/dist-packages (from faker) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.4->faker) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import faker\n",
    "import random\n",
    " \n",
    "import pandas as pd\n",
    "\n",
    "N_PROBS = 2000\n",
    "  \n",
    "def generate_person(f):\n",
    "    \n",
    "    plec = f.random_element(elements=(\"K\", \"M\"))\n",
    "    if plec == 'M':\n",
    "        imie = f.first_name_male()\n",
    "        nazwisko = f.last_name_male()\n",
    "    else:\n",
    "        imie = f.first_name_female()\n",
    "        nazwisko = f.last_name_female()\n",
    "    wiek = random.randint(25, 65)\n",
    "    person = {\n",
    "        'imie': imie,\n",
    "        'nazwisko': nazwisko,\n",
    "        'wiek': wiek,\n",
    "        'plec': plec,\n",
    "        'dom': {\n",
    "            'ulica': f.street_name(),\n",
    "            'numer_domu': f.building_number(),\n",
    "            'kod_pocztowy': f.postcode(),\n",
    "            'miasto': f.city(),\n",
    "            'wojewodztwo': f.region(),\n",
    "            'telefon': f.phone_number()\n",
    "        },\n",
    "        'praca': {\n",
    "            'firma': f.company(),\n",
    "            'stanowisko': f.job(),\n",
    "            'ulica': f.street_name(),\n",
    "            'numer_domu': f.building_number(),\n",
    "            'kod_pocztowy': f.postcode(),\n",
    "            'miasto': f.city(),\n",
    "            'telefon': f.phone_number(),\n",
    "            'wynagrodzenie': 200 * wiek + 100 * random.randint(-5, 5)\n",
    "        }\n",
    "    }\n",
    " \n",
    "    return person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘employees_dataset’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir employees_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = faker.Faker(['pl_PL'])\n",
    "for i in range(N_PROBS):\n",
    "    osoba = generate_person(fake)\n",
    "    with open(\"employees_dataset/%04d.json\" % (i+1), \"w\") as file:\n",
    "        json.dump(osoba, file)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .appName(\"Spark master\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------+----+--------------------+----+\n",
      "|                 dom|     imie|nazwisko|plec|               praca|wiek|\n",
      "+--------------------+---------+--------+----+--------------------+----+\n",
      "|[00-087, Tychy, 9...|Agnieszka| Wlaźlak|   K|[FPUH Goworek i s...|  35|\n",
      "+--------------------+---------+--------+----+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"employees_dataset/0001.json\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dom: struct (nullable = true)\n",
      " |    |-- kod_pocztowy: string (nullable = true)\n",
      " |    |-- miasto: string (nullable = true)\n",
      " |    |-- numer_domu: string (nullable = true)\n",
      " |    |-- telefon: string (nullable = true)\n",
      " |    |-- ulica: string (nullable = true)\n",
      " |    |-- wojewodztwo: string (nullable = true)\n",
      " |-- imie: string (nullable = true)\n",
      " |-- nazwisko: string (nullable = true)\n",
      " |-- plec: string (nullable = true)\n",
      " |-- praca: struct (nullable = true)\n",
      " |    |-- firma: string (nullable = true)\n",
      " |    |-- kod_pocztowy: string (nullable = true)\n",
      " |    |-- miasto: string (nullable = true)\n",
      " |    |-- numer_domu: string (nullable = true)\n",
      " |    |-- stanowisko: string (nullable = true)\n",
      " |    |-- telefon: string (nullable = true)\n",
      " |    |-- ulica: string (nullable = true)\n",
      " |    |-- wynagrodzenie: long (nullable = true)\n",
      " |-- wiek: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"employees_dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------+----+--------------------+----+\n",
      "|                 dom|    imie| nazwisko|plec|               praca|wiek|\n",
      "+--------------------+--------+---------+----+--------------------+----+\n",
      "|[38-713, Żyrardów...|Apolonia|Kamieniak|   K|[Spółdzielnia Kle...|  43|\n",
      "|[28-613, Wodzisła...|  Ernest|  Breguła|   M|[Fundacja Palusza...|  49|\n",
      "|[60-196, Świebodz...| Tadeusz|    Hajda|   M|[Drożdżal-Wrześni...|  29|\n",
      "+--------------------+--------+---------+----+--------------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|kod_pocztowy|kod_pocztowy|\n",
      "+------------+------------+\n",
      "|      38-713|      97-248|\n",
      "|      28-613|      78-521|\n",
      "|      60-196|      38-550|\n",
      "|      56-892|      96-325|\n",
      "|      88-302|      37-918|\n",
      "+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .select(\n",
    "        F.col('dom.kod_pocztowy'),\n",
    "        F.col('praca.kod_pocztowy'),\n",
    "    )\\\n",
    ".show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_we_need_for_modeling_df = df.select('wiek',F.col('praca.wynagrodzenie').alias('wynagrodzenie'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_we_need_for_modeling_df.write.parquet('employees.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_we_need_for_modeling_df\\\n",
    "    .repartition(1)\\\n",
    "    .write\\\n",
    "    .partitionBy(\"wiek\")\\\n",
    "    .parquet('employees-by-age.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
